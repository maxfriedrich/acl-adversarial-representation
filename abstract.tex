% !TeX root=main
% !TeX spellcheck=en_US

\begin{abstract}
%
De-identification is the task of detecting \ac{phi} in medical text.
%
Obtaining a large and diverse dataset for de-identification poses a challenge as privacy laws prohibit sharing of raw medical records.
%
We introduce two approaches to sharing training data for de-identification that do not require expensive manual pseudonymization: a naive automatic pseudonymization and an adversarial private representation.
%
A simple \acs{lstm}-\acs{crf} model trained on our automatically pseudonymized data achieves a $96.75\%$ de-identification \fone score on the i2b2 2014 dataset.
%
Our adversarial representation fulfills a stronger privacy criterion than the automatic pseudonymization approach while allowing to train a model to an \fone score of $97.4\%$, which is comparable to the non-private state of the art.
% TODO it's not really comparable, the SotA using ensemble+rules is 98.21
\end{abstract}
